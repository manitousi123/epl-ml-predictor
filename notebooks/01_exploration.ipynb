{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92651815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to path: C:\\Users\\Mani\\epl-ml-predictor\\src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()   # go up from /notebooks to project root\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "print(\"Added to path:\", SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651cd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1140, 133)\n",
      "  Div        Date   Time        HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
      "0  E0  05/08/2022  20:00  Crystal Palace        Arsenal     0     2   A     0   \n",
      "1  E0  06/08/2022  12:30          Fulham      Liverpool     2     2   D     1   \n",
      "2  E0  06/08/2022  15:00     Bournemouth    Aston Villa     2     0   H     1   \n",
      "3  E0  06/08/2022  15:00           Leeds         Wolves     2     1   H     1   \n",
      "4  E0  06/08/2022  15:00       Newcastle  Nott'm Forest     2     0   H     0   \n",
      "\n",
      "   HTAG  ... 1XBCH 1XBCD  1XBCA  BFECH  BFECD  BFECA  BFEC>2.5  BFEC<2.5  \\\n",
      "0     1  ...   NaN   NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
      "1     0  ...   NaN   NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
      "2     0  ...   NaN   NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
      "3     1  ...   NaN   NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
      "4     0  ...   NaN   NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
      "\n",
      "   BFECAHH  BFECAHA  \n",
      "0      NaN      NaN  \n",
      "1      NaN      NaN  \n",
      "2      NaN      NaN  \n",
      "3      NaN      NaN  \n",
      "4      NaN      NaN  \n",
      "\n",
      "[5 rows x 133 columns]\n",
      "SeasonFile\n",
      "22.23.csv    380\n",
      "23.24.csv    380\n",
      "24.25.csv    380\n",
      "Name: count, dtype: int64\n",
      "Index(['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR',\n",
      "       'HTHG', 'HTAG',\n",
      "       ...\n",
      "       '1XBCH', '1XBCD', '1XBCA', 'BFECH', 'BFECD', 'BFECA', 'BFEC>2.5',\n",
      "       'BFEC<2.5', 'BFECAHH', 'BFECAHA'],\n",
      "      dtype='object', length=133)\n",
      "['1XBA', '1XBCA', '1XBCD', '1XBCH', '1XBD', '1XBH', 'AvgA', 'AvgAHA', 'AvgAHH', 'AvgCA', 'AvgCAHA', 'AvgCAHH', 'AvgCD', 'AvgCH', 'AvgD', 'AvgH', 'B365A', 'B365AHA', 'B365AHH', 'B365CA', 'B365CAHA', 'B365CAHH', 'B365CD', 'B365CH', 'B365D', 'B365H', 'BFA', 'BFCA', 'BFCD', 'BFCH', 'BFD', 'BFEA', 'BFEAHA', 'BFEAHH', 'BFECA', 'BFECAHA', 'BFECAHH', 'BFECD', 'BFECH', 'BFED']\n"
     ]
    }
   ],
   "source": [
    "from data_loading import load_raw_matches\n",
    "\n",
    "df = load_raw_matches()\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df[\"SeasonFile\"].value_counts())\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087247f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FTR\n",
       " H    514\n",
       " A    364\n",
       " D    262\n",
       " Name: count, dtype: int64,\n",
       " FTR\n",
       " H    0.450877\n",
       " A    0.319298\n",
       " D    0.229825\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"FTR\"].value_counts(), df[\"FTR\"].value_counts(normalize=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62780558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FTR  Result\n",
      "0   A       2\n",
      "1   D       1\n",
      "2   H       0\n",
      "3   H       0\n",
      "4   H       0\n"
     ]
    }
   ],
   "source": [
    "target_map = {'H': 0, 'D': 1, 'A': 2}\n",
    "df[\"Result\"] = df[\"FTR\"].map(target_map)\n",
    "\n",
    "print(df[[\"FTR\", \"Result\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57796eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1XBA', '1XBCA', '1XBCD', '1XBCH', '1XBD', '1XBH', 'AvgA', 'AvgAHA', 'AvgAHH', 'AvgCA', 'AvgCAHA', 'AvgCAHH', 'AvgCD', 'AvgCH', 'AvgD', 'AvgH', 'B365A', 'B365AHA', 'B365AHH', 'B365CA', 'B365CAHA', 'B365CAHH', 'B365CD', 'B365CH', 'B365D', 'B365H', 'BFA', 'BFCA', 'BFCD', 'BFCH', 'BFD', 'BFEA', 'BFEAHA', 'BFEAHH', 'BFECA', 'BFECAHA', 'BFECAHH', 'BFECD', 'BFECH', 'BFED']\n"
     ]
    }
   ],
   "source": [
    "# Show all columns that look like home/draw/away odds\n",
    "odds_cols = [c for c in df.columns if c.endswith(\"H\") or c.endswith(\"D\") or c.endswith(\"A\")]\n",
    "print(sorted(odds_cols)[:40])  # first 40 just to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "767f644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1140, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.20</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.75</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.25</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.66</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B365H  B365D  B365A  Result\n",
       "0   4.20    3.6   1.85       2\n",
       "1  11.00    6.0   1.25       1\n",
       "2   3.75    3.5   2.00       0\n",
       "3   2.25    3.4   3.20       0\n",
       "4   1.66    3.8   5.25       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [\"B365H\", \"B365D\", \"B365A\"]\n",
    "\n",
    "model_df = df[feature_cols + [\"Result\"]].dropna()\n",
    "\n",
    "print(model_df.shape)\n",
    "model_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa4e2f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((912, 3), (228, 3))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = model_df[feature_cols]\n",
    "y = model_df[\"Result\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9369453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5614035087719298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69       103\n",
      "           1       0.00      0.00      0.00        52\n",
      "           2       0.54      0.53      0.54        73\n",
      "\n",
      "    accuracy                           0.56       228\n",
      "   macro avg       0.37      0.47      0.41       228\n",
      "weighted avg       0.43      0.56      0.48       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mani\\epl-ml-predictor\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Mani\\epl-ml-predictor\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Mani\\epl-ml-predictor\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=500,\n",
    "    solver=\"lbfgs\"   # supports multinomial automatically\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
